import streamlit as st
import pandas as pd
from sqlalchemy import create_engine
from dotenv import load_dotenv
import os
import plotly.express as px
from datetime import datetime, timedelta
import time
import json
import re
from typing import Dict  # Python 3.8 compatibility

load_dotenv()

st.set_page_config(page_title="Survey LMS Dashboard", page_icon="ğŸ“Š", layout="wide")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  SCHOOL NAME NORMALISATION ENGINE
#  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  3-layer strategy:
#   1. Hard alias table  (built from every variant in your real SQL dump)
#   2. Zero-width / invisible-char stripping  (handles ZWSP embedded by phones)
#   3. "ğŸ« School Mapping" UI tab to add new aliases at runtime
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ALIAS_FILE = "school_aliases_custom.json"

# â”€â”€â”€ canonical school names â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
C = {
    "chatumuk": "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á…áá»á˜á»á",
    "aranh": "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á¢ášá‰áŸ’á‰ášá„áŸ’áŸá¸",
    "preakleab": "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€á›áŸ€á”",
    "preakdambang": "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€áŠáŸ†á”á„",
    "preahangdong": "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„",
    "ksachsa": "áœá·á‘áŸ’á™á¶á›áŸá™ááŸ’áŸá¶á…áŸ‹áŸ",
    "sokhan_khvav": "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ááŸ’áœá¶áœ",
    "sokhan_tonlap": "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“á‘á“áŸ’á›á¶á”áŸ‹",
    "sokhan_tramknar": "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ááŸ’ášá¶áŸ†ááŸ’á“á¶áš",
    "sokhan_preysandaek": "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“á–áŸ’ášáŸƒáŸááŸ’ááŸ‚á€",
    "sokhan_doungkhpos": "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“áŠá¼á„ááŸ’á–áŸáŸ‹á”á¼ášá¸á‡á›áŸá¶áš",
    "hunsaen_sereipheap": "áœá·á‘áŸ’á™á¶á›áŸá™á áŸŠá»á“áŸáŸ‚á“áŸáŸášá¸á—á¶á–",
    "hunsaen_1mithuna": "áœá·á‘áŸ’á™á¶á›áŸá™á áŸŠá»á“áŸáŸ‚á“áŸ¡á˜á·áá»á“á¶",
    "bunrany": "áœá·á‘áŸ’á™á¶á›áŸá™á”á»ááŸ’á™ášáŸ‰á¶á“á¸á áŸŠá»á“áŸáŸ‚á“á—áŸ’á“áŸ†á‡á¸áŸá¼áš",
    "haspveam": "áœá·á‘áŸ’á™á¶á›áŸá™á áŸ á–á¶á˜á‡á¸á€á„",
    "lve": "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á›áŸ’áœáŸ",
}

# â”€â”€â”€ alias table: every raw variant â†’ canonical â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ALL variants found in your live SQL dump are included.
SCHOOL_ALIASES_BUILTIN: Dict[str, str] = {
    # â•â• á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á…áá»á˜á»á â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "á£á“á»áœá·á‘áŸ’á™á¶á›áŸá™á…áá»á˜á»á": C["chatumuk"],  # á£ vs á¢
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™ á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á». á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á».á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á» á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á»á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á»áœ.á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á»áœá·.á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á»áœá·á‘áŸ’á™á¶á›á™áŸá…áá»á˜á»á": C["chatumuk"],  # á›á™áŸ typo
    "á¢á“á»áœá·á¡á¶á›áŸá™á…áá»á˜á»á": C["chatumuk"],  # áœá·á¡ typo
    "áŸá¶á›á¶ á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™ á…áá»á˜á»á": C["chatumuk"],
    "áŸá¶á›á¶á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™ á…áá»á˜á»á": C["chatumuk"],
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™â€‹á…áá»á˜á»á": C["chatumuk"],  # ZWSP after á›áŸá™
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™â€‹á…áá»á˜á»áâ€‹": C["chatumuk"],  # trailing ZWSP too
    # â•â• á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á¢ášá‰áŸ’á‰ášá„áŸ’áŸá¸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á¢ášá‰áŸ’á‰ášá„áŸ’áŸá¸": C["aranh"],
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™ á¢ášá‰áŸ’á‰ášá„áŸ’áŸá¸": C["aranh"],
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á¢ášá‰áŸ’á‰ášá„áŸ’áŸá¸": C["aranh"],  # á›áŸ typo
    "áŸá¶á›á¶á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á¢ášá‰áŸ’á‰ášá„áŸ’áŸá¸": C["aranh"],
    "áŸá¶á›á¶á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á¢ášá‰áŸ’á‰ášá„áŸ’áŸáŸŠá¸": C["aranh"],  # áŸáŸŠá¸ variant
    "ARS": C["aranh"],  # abbreviation in DB
    # â•â• áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„": C["preahangdong"],
    "áœá·.á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„": C["preahangdong"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„": C["preahangdong"],
    "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡ á¢á„áŸ’á‚ áŒá½á„": C["preahangdong"],
    "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡ á¢á„áŸ’á‚áŒá½á„": C["preahangdong"],
    "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá¼á„": C["preahangdong"],  # áŒá¼ typo
    "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„(NGS)": C["preahangdong"],
    "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„á€á˜áŸ’á˜áœá·á’á¸á‡áŸ†á“á¶á“áŸ‹ááŸ’á˜á¸": C["preahangdong"],
    "áŸá¶á›á¶ášáŸ€á“á‡áŸ†á“á¶á“áŸ‹ááŸ’á˜á¸á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„": C["preahangdong"],
    "áŸá¶á›á¶áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‡á¢á„áŸ’á‚áŒá½á„": C["preahangdong"],
    # â•â• áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€á›áŸ€á” â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€á›áŸ€á”": C["preakleab"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ á–áŸ’ášáŸ‚á€á›áŸ€á”": C["preakleab"],
    "á€á˜áŸ’á˜áœá·á’á¸áŸá¶á›á¶ášáŸ€á“á‡áŸ†á“á¶á“áŸ‹ááŸ’á˜á¸ áœá·á‘áŸ’á™á¶á›áŸá™ á–áŸ’ášáŸ‚á€á›áŸ€á”": C["preakleab"],
    "áœá·á‘áŸ’á™á¶á›áŸá™â€‹á‡áŸ†á“á¶á“áŸ‹ááŸ’á˜á¸â€‹á–áŸ’ášáŸ‚á€á›áŸ€á”â€‹": C["preakleab"],  # ZWSP chars
    # â•â• á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€áŠáŸ†á”á„ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™ á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],
    "áŸá¶á›á¶á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],
    "áŸá¶á›á¶á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™ á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],
    "á¢á“á».á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],
    "á¢á“á»á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],
    "á¢á“á»á–áŸ’ášáŸ‚á€ááŸ†á”á„": C["preakdambang"],  # ááŸ† typo
    "á¢á“á»á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],  # missing áœá·
    "á¢á“á»áœá·á‘áŸ’á™á¶á›á™áŸ á–áŸ’ášáŸ‚á€áŠáŸ†á”á„": C["preakdambang"],  # á›á™áŸ typo
    "á£á“á»áœá·á‘áŸ’á™á¶á›áŸá™á–áŸ’ášáŸá€áŠáŸ†á”á„": C["preakdambang"],  # á–áŸ’ášáŸ typo + á£
    # â•â• áœá·á‘áŸ’á™á¶á›áŸá™ááŸ’áŸá¶á…áŸ‹áŸ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™ááŸ’áŸá¶á…áŸ‹áŸ": C["ksachsa"],
    "áœá·.ááŸ’áŸá¶á…áŸ‹áŸ": C["ksachsa"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ ááŸ’áŸá¶á…áŸ‹áŸ": C["ksachsa"],
    "áœá·á‘áŸ’á™á¶á›áŸá™â€‹ááŸ’áŸá¶á…áŸ‹áŸ": C["ksachsa"],  # ZWSP
    "áœá·á‘áŸ’á™á¶á›áŸá™â€‹ááŸ’áŸá¶á…áŸ‹â€‹áŸâ€‹": C["ksachsa"],  # multiple ZWSP
    "áœá·á‘áŸ’á™á¶á›áŸá™ááŸ’áŸá¶á…áŸ‹áŸâ€‹": C["ksachsa"],  # trailing ZWSP
    "áŸá¶á›á¶áœá·á‘áŸ’á™á¶á›áŸá™ááŸ’áŸá¶á…áŸ‹áŸ": C["ksachsa"],
    # â•â• áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ááŸ’áœá¶áœ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ááŸ’áœá¶áœ": C["sokhan_khvav"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»á á¢á¶á“ ááŸ’áœá¶áœ": C["sokhan_khvav"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»áá¢á¶á“ ááŸ’áœá¶áœ": C["sokhan_khvav"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»áá¢á¶á“ááŸ’áœá¶áœ": C["sokhan_khvav"],
    "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ ááŸ’áœá¶áœ": C["sokhan_khvav"],
    "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»á á¢á¶á“ááŸ’áœá¶áœ": C["sokhan_khvav"],
    "áœá·á‘áŸ’á™á¶á›áŸá™â€‹áŸá»áá¢á¶á“ááŸ’áœá¶áœ": C["sokhan_khvav"],  # ZWSP
    "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ááŸ’áœá¶": C["sokhan_khvav"],  # missing áœ
    # â•â• áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“á‘á“áŸ’á›á¶á”áŸ‹ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“á‘á“áŸ’á›á¶á”áŸ‹": C["sokhan_tonlap"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»á á¢á¶á“ á‘á“áŸ’á›á¶á”áŸ‹": C["sokhan_tonlap"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»áá¢á¶á“á‘á“áŸ’á›á¶á”áŸ‹": C["sokhan_tonlap"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»áá¢á¶á“ á‘á“áŸ’á›á¶á”áŸ‹": C["sokhan_tonlap"],
    # â•â• áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ááŸ’ášá¶áŸ†ááŸ’á“á¶áš â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»áá¢á¶á“ááŸ’ášá¶áŸ†ááŸ’á“á¶áš": C["sokhan_tramknar"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»áá¢á¶á“ááŸ’ášá¶áŸ†ááŸ’á“á¶áš": C["sokhan_tramknar"],
    "áœá·á‘áŸ’á™á¶á›áŸá™áŸá»á á¢á¶á“ááŸ’ášá¶áŸ†ááŸ’á“á¶áš": C["sokhan_tramknar"],
    "áœá·á‘áŸ’á™á¶á›á™áŸáŸá»áá¢á¶á“ááŸ’ášá¶áŸ†ááŸ’á“á¶áš": C["sokhan_tramknar"],  # á›á™áŸ typo
    # â•â• áœá·á‘áŸ’á™á¶á›áŸá™á áŸŠá»á“áŸáŸ‚á“áŸáŸášá¸á—á¶á– â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™á áŸŠá»á“áŸáŸ‚á“áŸáŸášá¸á—á¶á–": C["hunsaen_sereipheap"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ á áŸŠá»á“ áŸáŸ‚á“ áŸáŸášá¸á—á¶á–": C["hunsaen_sereipheap"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ á áŸŠá»á“áŸáŸ‚á“áŸáŸášá¸á—á¶á–": C["hunsaen_sereipheap"],
    "áœá·á‘áŸ’á™á¶á›áŸá™á áŸŠá»á“ áŸáŸ‚á“áŸáŸášá¸á—á¶á–": C["hunsaen_sereipheap"],
    "áœá·á‘áŸ’á™á¶á›á™áŸá áŸŠá»á“áŸáŸ‚á“áŸáŸášá¸á—á¶á–": C["hunsaen_sereipheap"],  # á›á™áŸ typo
    "áœá·á‘áŸ’á™á¶á›áŸá™â€‹á áŸŠá»á“â€‹áŸáŸ‚á“â€‹áŸáŸášá¸á—á¶á–â€‹": C["hunsaen_sereipheap"],  # ZWSP
    "áŸá¶á›á¶áœá·á‘áŸ’á™á¶á›áŸá™â€‹ á áŸŠá»á“áŸáŸ‚á“â€‹ áŸáŸášá¸á—á¶á–â€‹": C["hunsaen_sereipheap"],
    # â•â• Single-entry schools â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    "áœá·á‘áŸ’á™á¶á›áŸá™á áŸŠá»á“áŸáŸ‚á“áŸ¡á˜á·áá»á“á¶": C["hunsaen_1mithuna"],
    "áœá·á‘áŸ’á™á¶á›áŸá™á”áŸ‘á»á“ášáŸ‰á¶á“á¸á áŸ‘á»á“áŸáŸ‚á“á—áŸ’á“áŸ†á‡á¸áŸá¼áš": C["bunrany"],
    "áœá·á‘áŸ’á™á¶á›áŸá™â€‹ á áŸâ€‹ á–á¶á˜á‡á¸á€á„": C["haspveam"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»á á¢á¶á“á–áŸ’ášáŸƒáŸááŸ’ááŸ‚á€": C["sokhan_preysandaek"],
    "áœá·á‘áŸ’á™á¶á›áŸá™ áŸá»á á¢á¶á“ áŠá¼á„ááŸ’á–áŸáŸ‹á”á¼ášá¸á‡á›áŸá¶áš": C["sokhan_doungkhpos"],
    "á¢á“á»áœá·á‘áŸ’á™á¶á›áŸá™á›áŸ’áœáŸ": C["lve"],
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Normalisation helpers
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_INVISIBLE = re.compile(
    r"[\u200b\u200c\u200d\u00ad\ufeff\u2060\u180e\u2028\u2029]",
    re.UNICODE,
)


def strip_invisible(text: str) -> str:
    """Remove zero-width and other invisible Unicode characters."""
    return _INVISIBLE.sub("", text)


def normalize_key(text: str) -> str:
    """
    Lookup key: strip invisible chars, collapse ALL whitespace to nothing,
    lower-case. This collapses space variants and ZWSP in one step.
    """
    if not isinstance(text, str):
        return str(text)
    return re.sub(r"\s+", "", strip_invisible(text)).lower()


def load_custom_aliases() -> dict:
    if os.path.exists(ALIAS_FILE):
        try:
            with open(ALIAS_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            return {}
    return {}


def save_custom_aliases(aliases: dict):
    with open(ALIAS_FILE, "w", encoding="utf-8") as f:
        json.dump(aliases, f, ensure_ascii=False, indent=2)


def get_all_aliases() -> dict:
    merged = dict(SCHOOL_ALIASES_BUILTIN)
    merged.update(load_custom_aliases())
    return merged


def build_fast_lookup(alias_map: dict) -> dict:
    return {normalize_key(k): v for k, v in alias_map.items()}


def resolve_school(raw: str, fast_lookup: dict, alias_map: dict) -> str:
    if not isinstance(raw, str):
        return str(raw)
    # 1. exact match (fastest)
    if raw in alias_map:
        return alias_map[raw]
    # 2. space / ZWSP stripped match
    key = normalize_key(raw)
    if key in fast_lookup:
        return fast_lookup[key]
    # 3. fallback: at least strip invisible chars & tidy whitespace
    return re.sub(r"\s+", " ", strip_invisible(raw).strip())


def apply_normalization(df: pd.DataFrame) -> pd.DataFrame:
    alias_map = get_all_aliases()
    fast_lookup = build_fast_lookup(alias_map)
    df = df.copy()
    df["school_raw"] = df["school_name"]  # keep original for audit
    df["school_name"] = df["school_name"].apply(
        lambda x: resolve_school(x, fast_lookup, alias_map)
    )
    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  DATABASE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def get_connection_string():
    return (
        f"mysql+pymysql://{os.getenv('MYSQL_USER')}:{os.getenv('MYSQL_PASSWORD')}"
        f"@{os.getenv('MYSQL_HOST')}:{os.getenv('MYSQL_PORT')}"
        f"/{os.getenv('MYSQL_DATABASE')}?charset=utf8mb4"
    )


@st.cache_data(ttl=60)
def fetch_data():
    max_retries, retry_delay = 3, 2
    for attempt in range(max_retries):
        try:
            engine = create_engine(
                get_connection_string(),
                pool_pre_ping=True,
                pool_recycle=3600,
                connect_args={"connect_timeout": 10},
            )
            df = pd.read_sql(
                "SELECT * FROM survey_responses ORDER BY created_at DESC", engine
            )
            engine.dispose()
            df = apply_normalization(df)  # â† normalise immediately after fetch
            return df
        except Exception as e:
            if attempt < max_retries - 1:
                st.warning(f"Retryingâ€¦ ({attempt + 1}/{max_retries})")
                time.sleep(retry_delay)
            else:
                st.error(f"âŒ Failed to connect: {e}")
                st.info("Check if MySQL is running: `docker ps`")
                return pd.DataFrame()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MAIN APP
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


def main():
    st.title("ğŸ“Š Survey LMS Dashboard")
    st.markdown("---")

    col1, col2, _ = st.columns([1, 1, 4])
    with col1:
        if st.button("ğŸ”„ Refresh Data"):
            st.cache_data.clear()
            st.rerun()
    with col2:
        try:
            from sqlalchemy import text

            engine = create_engine(
                get_connection_string(), connect_args={"connect_timeout": 10}
            )
            with engine.connect() as conn:
                conn.execute(text("SELECT 1"))
            st.success("âœ… Connected")
            engine.dispose()
        except Exception as e:
            st.error(f"âŒ DB Offline: {e}")
            st.stop()

    try:
        df = fetch_data()
        if df.empty:
            st.warning("No survey responses yet.")
            return

        # â”€â”€ SIDEBAR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.sidebar.header("ğŸ” Filters")

        # School dropdown uses canonical names â†’ no duplicates
        schools = ["All"] + sorted(df["school_name"].unique().tolist())
        selected_school = st.sidebar.selectbox("School Name", schools)
        classes = ["All"] + sorted(df["class_name"].unique().tolist())
        selected_class = st.sidebar.selectbox("Class", classes)
        computer_options = ["All", "á€. á’áŸ’á›á¶á”áŸ‹", "á. á˜á·á“á’áŸ’á›á¶á”áŸ‹"]
        selected_computer = st.sidebar.selectbox(
            "Computer Experience", computer_options
        )

        st.sidebar.subheader("Date Range")
        date_option = st.sidebar.radio(
            "Select period:",
            ["All time", "Last 7 days", "Last 30 days", "Custom range"],
        )

        # â”€â”€ APPLY FILTERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        filtered_df = df.copy()
        if selected_school != "All":
            filtered_df = filtered_df[filtered_df["school_name"] == selected_school]
        if selected_class != "All":
            filtered_df = filtered_df[filtered_df["class_name"] == selected_class]
        if selected_computer != "All":
            filtered_df = filtered_df[
                filtered_df["computer_usage"] == selected_computer
            ]

        if date_option == "Last 7 days":
            filtered_df = filtered_df[
                filtered_df["created_at"] >= datetime.now() - timedelta(days=7)
            ]
        elif date_option == "Last 30 days":
            filtered_df = filtered_df[
                filtered_df["created_at"] >= datetime.now() - timedelta(days=30)
            ]
        elif date_option == "Custom range":
            c1, c2 = st.sidebar.columns(2)
            start_date = c1.date_input("From")
            end_date = c2.date_input("To")
            filtered_df = filtered_df[
                (filtered_df["created_at"].dt.date >= start_date)
                & (filtered_df["created_at"].dt.date <= end_date)
            ]

        # â”€â”€ KEY METRICS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.header("ğŸ“ˆ Key Metrics")
        m1, m2, m3, m4 = st.columns(4)
        with m1:
            st.metric("Total Responses", len(filtered_df))
        with m2:
            no_computer = len(filtered_df[filtered_df["computer_usage"] == "á. á˜á·á“á’áŸ’á›á¶á”áŸ‹"])
            st.metric("No Computer Experience", no_computer)
        with m3:
            st.metric("Schools (unique)", filtered_df["school_name"].nunique())
        with m4:
            if not filtered_df.empty:
                latest = filtered_df["created_at"].max()
                hours_ago = int((datetime.now() - latest).total_seconds() / 3600)
                st.metric("Latest Response", f"{hours_ago}h ago")

        st.markdown("---")

        # â”€â”€ TABS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        tab1, tab2, tab3, tab4, tab5 = st.tabs(
            [
                "ğŸ“Š Overview",
                "â“ Questions",
                "ğŸ“… Timeline",
                "ğŸ” Custom Queries",
                "ğŸ« School Mapping",
            ]
        )

        # TAB 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab1:
            col1, col2 = st.columns(2)
            with col1:
                sc = filtered_df["school_name"].value_counts().reset_index()
                sc.columns = ["School", "Responses"]
                fig = px.bar(
                    sc,
                    x="School",
                    y="Responses",
                    title="Responses by School (duplicates merged)",
                    color="Responses",
                    color_continuous_scale="Blues",
                )
                fig.update_layout(xaxis_tickangle=-30)
                st.plotly_chart(fig, use_container_width=True)
            with col2:
                cc = filtered_df["computer_usage"].value_counts().reset_index()
                cc.columns = ["Experience", "Count"]
                st.plotly_chart(
                    px.pie(
                        cc,
                        names="Experience",
                        values="Count",
                        title="Computer Usage Distribution",
                    ),
                    use_container_width=True,
                )

        # TAB 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab2:
            answered = filtered_df[filtered_df["question_1"] != "N/A"]
            if len(answered) == 0:
                st.info("No completed responses in current filter.")
            else:
                col1, col2 = st.columns(2)
                with col1:
                    q1 = answered["question_1"].value_counts().reset_index()
                    q1.columns = ["Answer", "Count"]
                    st.plotly_chart(
                        px.bar(q1, x="Answer", y="Count", title="Q1: Study Hours"),
                        use_container_width=True,
                    )
                with col2:
                    q2 = answered["question_2"].value_counts().reset_index()
                    q2.columns = ["Answer", "Count"]
                    st.plotly_chart(
                        px.pie(
                            q2,
                            names="Answer",
                            values="Count",
                            title="Q2: Learning Method",
                        ),
                        use_container_width=True,
                    )

        # TAB 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab3:
            tl = filtered_df.copy()
            tl["date"] = tl["created_at"].dt.date
            daily = tl.groupby("date").size().reset_index()
            daily.columns = ["Date", "Responses"]
            st.plotly_chart(
                px.line(
                    daily,
                    x="Date",
                    y="Responses",
                    title="Daily Responses",
                    markers=True,
                ),
                use_container_width=True,
            )

        # TAB 4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab4:
            # â”€â”€ 1. School vs Computer Usage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.subheader("ğŸ« School vs Computer Usage")

            # Build clean cross-tab: only á€. á’áŸ’á›á¶á”áŸ‹ and á. á˜á·á“á’áŸ’á›á¶á”áŸ‹ columns
            comp_yes = "á€. á’áŸ’á›á¶á”áŸ‹"
            comp_no = "á. á˜á·á“á’áŸ’á›á¶á”áŸ‹"

            def school_computer_table(df_in):
                grp = (
                    df_in.groupby("school_name")["computer_usage"]
                    .value_counts()
                    .unstack(fill_value=0)
                )
                for col in [comp_yes, comp_no]:
                    if col not in grp.columns:
                        grp[col] = 0
                grp = grp[[comp_yes, comp_no]].copy()
                grp.index.name = "School Name"
                grp["Total"] = grp[comp_yes] + grp[comp_no]
                grp["% á’áŸ’á›á¶á”áŸ‹"] = (grp[comp_yes] / grp["Total"] * 100).round(1).astype(
                    str
                ) + "%"
                grp["% á˜á·á“á’áŸ’á›á¶á”áŸ‹"] = (grp[comp_no] / grp["Total"] * 100).round(1).astype(
                    str
                ) + "%"
                grp = grp.reset_index()
                grp.columns = [
                    "School Name",
                    "á€. á’áŸ’á›á¶á”áŸ‹",
                    "á. á˜á·á“á’áŸ’á›á¶á”áŸ‹",
                    "Total",
                    "% á’áŸ’á›á¶á”áŸ‹",
                    "% á˜á·á“á’áŸ’á›á¶á”áŸ‹",
                ]
                return grp.sort_values("Total", ascending=False).reset_index(drop=True)

            comp_table = school_computer_table(filtered_df)
            st.dataframe(comp_table, use_container_width=True, hide_index=True)

            # Bar chart
            fig_comp = px.bar(
                comp_table,
                x="School Name",
                y=["á€. á’áŸ’á›á¶á”áŸ‹", "á. á˜á·á“á’áŸ’á›á¶á”áŸ‹"],
                title="Computer Experience by School",
                barmode="stack",
                color_discrete_map={"á€. á’áŸ’á›á¶á”áŸ‹": "#2196F3", "á. á˜á·á“á’áŸ’á›á¶á”áŸ‹": "#FF5722"},
            )
            fig_comp.update_layout(xaxis_tickangle=-30, legend_title="Experience")
            st.plotly_chart(fig_comp, use_container_width=True)

            # â”€â”€ 2. Teachers Without Computer Experience â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.markdown("---")
            st.subheader("ğŸ™‹ Teachers Without Computer Experience")
            no_comp = filtered_df[filtered_df["computer_usage"] == comp_no]
            st.metric("Count", len(no_comp))
            if len(no_comp) > 0:
                st.dataframe(
                    no_comp[["full_name", "school_name", "class_name", "created_at"]],
                    use_container_width=True,
                )

            # â”€â”€ 3. Quiz Score per Teacher â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.markdown("---")
            st.subheader("ğŸ“ Quiz Score per Teacher (Q1â€“Q8)")
            st.caption(
                "Only teachers who have computer experience and answered questions are scored."
            )

            # Correct answers map
            CORRECT = {
                "question_1": "á. á…á»á… File -> á‡áŸ’ášá¾áŸášá¾áŸ New (ááŸ’á˜á¸) -> Blank Document",
                "question_2": "á‚. á…á»á… File â†’ Save As -> áŠá¶á€áŸ‹áˆáŸ’á˜áŸ„áŸ‡á¯á€áŸá¶áš -> Save á¬ Ctrl + S",
                "question_3": "á. á…á»á… File â†’ Open (á”á¾á€) -> á‡áŸ’ášá¾áŸášá¾áŸáˆáŸ’á˜áŸ„áŸ‡ -> Open",
                "question_4": "á. á‚áá“á¶ á“á·á„áœá·á—á¶á‚á‘á·á“áŸ’á“á“áŸá™",
                "question_5": "á‚. = Cell + Cell á¬ =Sum(Cell:Cell)",
                "question_6": "á€. Login user",
                "question_7": "á‚. áœá¸áŠáŸá¢á¼ áŸá„áŸ’ááŸá”á˜áŸášáŸ€á“ ášá„áŸ’áœá¶á™áá˜áŸ’á›áŸƒ á“á·á„á€á·á…áŸ’á…á€á¶ášá•áŸ’á‘áŸ‡",
                "question_8": "á€. á…áŸá‰á–á¸áŸáŸ€áœá—áŸ…á–á»á˜áŸ’á–ášá”áŸáŸ‹á€áŸ’ášáŸá½á„",
            }

            scored_df = filtered_df[filtered_df["question_1"] != "N/A"].copy()

            if scored_df.empty:
                st.info("No answered responses in current filter.")
            else:
                # Score each row
                for q, correct in CORRECT.items():
                    scored_df[f"{q}_correct"] = (
                        scored_df[q].str.strip() == correct.strip()
                    )

                scored_df["score"] = scored_df[[f"{q}_correct" for q in CORRECT]].sum(
                    axis=1
                )
                scored_df["score_pct"] = (
                    scored_df["score"] / len(CORRECT) * 100
                ).round(1)

                # â”€â”€ Per-teacher score table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                score_cols = ["full_name", "school_name", "score", "score_pct"] + [
                    f"{q}_correct" for q in CORRECT
                ]
                score_display = scored_df[score_cols].copy()
                score_display.columns = ["áˆáŸ’á˜áŸ„áŸ‡", "áŸá¶á›á¶", "á–á·á“áŸ’á‘á» (/ 8)", "á—á¶á‚ášá™ (%)"] + [
                    f"Q{i + 1}" for i in range(len(CORRECT))
                ]

                # Colour True/False
                def colour_bool(val):
                    if val is True:
                        return "background-color: #c8e6c9; color: #1b5e20"
                    elif val is False:
                        return "background-color: #ffcdd2; color: #b71c1c"
                    return ""

                bool_cols = [f"Q{i + 1}" for i in range(len(CORRECT))]
                st.dataframe(
                    score_display.style.applymap(colour_bool, subset=bool_cols),
                    use_container_width=True,
                    height=400,
                )

                # â”€â”€ Score summary by school â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                st.markdown("---")
                st.subheader("ğŸ“Š Average Score by School")
                school_score = (
                    scored_df.groupby("school_name")
                    .agg(
                        Teachers=("score", "count"),
                        Avg_Score=("score", "mean"),
                        Avg_Pct=("score_pct", "mean"),
                    )
                    .round(1)
                    .reset_index()
                    .rename(
                        columns={
                            "school_name": "School Name",
                            "Avg_Score": "Avg Score (/ 8)",
                            "Avg_Pct": "Avg %",
                        }
                    )
                    .sort_values("Avg %", ascending=False)
                )
                st.dataframe(school_score, use_container_width=True, hide_index=True)

                fig_score = px.bar(
                    school_score,
                    x="School Name",
                    y="Avg %",
                    title="Average Quiz Score % by School",
                    color="Avg %",
                    color_continuous_scale="RdYlGn",
                    range_color=[0, 100],
                    text="Avg %",
                )
                fig_score.update_traces(texttemplate="%{text}%", textposition="outside")
                fig_score.update_layout(xaxis_tickangle=-30)
                st.plotly_chart(fig_score, use_container_width=True)

            # â”€â”€ 4. Q9 â€” How much has EBC helped? â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.markdown("---")
            st.subheader("ğŸ“Š Q9: EBC á‡á½á™á€á¶ášá”á„áŸ’ášáŸ€á“á”áŸ‰á»á“áŸ’á˜á¶á“á—á¶á‚ášá™?")

            Q9_OPTIONS = {
                "á€. áŸ¡áŸ % á‘áŸ… áŸ£áŸ %": "á€. áŸ¡áŸ %â€“áŸ£áŸ %",
                "á. áŸ¤áŸ % á‘áŸ… áŸ¦áŸ %": "á. áŸ¤áŸ %â€“áŸ¦áŸ %",
                "á‚. áŸ§áŸ % á‘áŸ… áŸ¡áŸ áŸ %": "á‚. áŸ§áŸ %â€“áŸ¡áŸ áŸ %",
            }

            q9_df = filtered_df[filtered_df["question_9"] != "N/A"].copy()

            if q9_df.empty:
                st.info("No Q9 responses in current filter.")
            else:
                # Overall Q9 distribution
                q9_counts = q9_df["question_9"].value_counts().reset_index()
                q9_counts.columns = ["Answer", "Count"]
                q9_counts["Label"] = (
                    q9_counts["Answer"].map(Q9_OPTIONS).fillna(q9_counts["Answer"])
                )
                q9_total = q9_counts["Count"].sum()
                q9_counts["Percent"] = (q9_counts["Count"] / q9_total * 100).round(1)

                col_a, col_b = st.columns(2)
                with col_a:
                    st.markdown("**Overall Distribution**")
                    for _, row in q9_counts.sort_values("Answer").iterrows():
                        label = Q9_OPTIONS.get(row["Answer"], row["Answer"])
                        st.metric(
                            label, f"{row['Count']} teachers", f"{row['Percent']}%"
                        )

                with col_b:
                    fig_q9 = px.pie(
                        q9_counts,
                        names="Label",
                        values="Count",
                        title="Q9 Distribution",
                        color_discrete_sequence=["#4CAF50", "#2196F3", "#FF9800"],
                    )
                    st.plotly_chart(fig_q9, use_container_width=True)

                # Q9 breakdown by school
                st.markdown("**Q9 Breakdown by School**")
                q9_school = (
                    q9_df.groupby(["school_name", "question_9"])
                    .size()
                    .unstack(fill_value=0)
                    .reset_index()
                )
                q9_school.columns.name = None
                # Ensure all 3 option columns exist
                for opt in Q9_OPTIONS:
                    if opt not in q9_school.columns:
                        q9_school[opt] = 0
                q9_school = q9_school[["school_name"] + list(Q9_OPTIONS.keys())].copy()
                q9_school["Total"] = q9_school[list(Q9_OPTIONS.keys())].sum(axis=1)
                for opt, lbl in Q9_OPTIONS.items():
                    q9_school[f"% {lbl}"] = (
                        q9_school[opt] / q9_school["Total"] * 100
                    ).round(1).astype(str) + "%"
                q9_school = q9_school.rename(columns={"school_name": "School Name"})
                st.dataframe(q9_school, use_container_width=True, hide_index=True)

                fig_q9s = px.bar(
                    q9_school,
                    x="School Name",
                    y=list(Q9_OPTIONS.keys()),
                    title="Q9 by School â€” How much has EBC helped?",
                    barmode="stack",
                    color_discrete_map={
                        "á€. áŸ¡áŸ % á‘áŸ… áŸ£áŸ %": "#FF5722",
                        "á. áŸ¤áŸ % á‘áŸ… áŸ¦áŸ %": "#2196F3",
                        "á‚. áŸ§áŸ % á‘áŸ… áŸ¡áŸ áŸ %": "#4CAF50",
                    },
                )
                fig_q9s.update_layout(xaxis_tickangle=-30, legend_title="Q9 Answer")
                st.plotly_chart(fig_q9s, use_container_width=True)

            # â”€â”€ 5. Unresolved school names (diagnostic) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            st.markdown("---")
            with st.expander("ğŸ”€ Name Variants Merged / Unresolved (diagnostic)"):
                if "school_raw" in filtered_df.columns:
                    vdf = (
                        filtered_df[
                            filtered_df["school_raw"] != filtered_df["school_name"]
                        ][["school_raw", "school_name"]]
                        .drop_duplicates()
                        .rename(
                            columns={
                                "school_raw": "As Written",
                                "school_name": "Canonical",
                            }
                        )
                        .sort_values("Canonical")
                    )
                    if vdf.empty:
                        st.success("âœ… No variants in current filter.")
                    else:
                        st.dataframe(vdf, use_container_width=True)

                all_canonical = set(get_all_aliases().values())
                unresolved = (
                    filtered_df[~filtered_df["school_name"].isin(all_canonical)][
                        "school_name"
                    ]
                    .value_counts()
                    .reset_index()
                )
                unresolved.columns = ["School Name", "Count"]
                if unresolved.empty:
                    st.success("âœ… All school names resolved.")
                else:
                    st.warning(
                        f"{len(unresolved)} unresolved â€” add in ğŸ« School Mapping tab."
                    )
                    st.dataframe(unresolved, use_container_width=True)

        # TAB 5 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with tab5:
            st.subheader("ğŸ« School Name Alias Manager")
            st.info(
                "When a teacher writes a school name in a new way, add it here.  \n"
                "Changes take effect after **ğŸ”„ Refresh Data**."
            )

            custom_aliases = load_custom_aliases()

            with st.form("add_alias_form", clear_on_submit=True):
                st.markdown("**â• Add New Alias**")
                c1, c2 = st.columns(2)
                new_raw = c1.text_input(
                    "Alias (as typed by teacher)", placeholder="e.g. áœá·.ááŸ’áŸá¶á…áŸ‹ áŸ"
                )
                new_canonical = c2.text_input(
                    "Canonical (official) name", placeholder="e.g. áœá·á‘áŸ’á™á¶á›áŸá™ááŸ’áŸá¶á…áŸ‹áŸ"
                )
                if st.form_submit_button("âœ… Save Alias"):
                    if new_raw.strip() and new_canonical.strip():
                        custom_aliases[new_raw.strip()] = new_canonical.strip()
                        save_custom_aliases(custom_aliases)
                        st.cache_data.clear()
                        st.success(f"Saved: **{new_raw}** â†’ **{new_canonical}**")
                        st.rerun()
                    else:
                        st.warning("Both fields are required.")

            st.markdown("---")
            st.markdown("**ğŸ“‹ Your Custom Aliases**")
            if custom_aliases:
                ca_df = pd.DataFrame(
                    list(custom_aliases.items()),
                    columns=["Alias (Raw)", "Canonical Name"],
                )
                st.dataframe(ca_df, use_container_width=True)
                del_key = st.selectbox(
                    "Select alias to delete",
                    ["â€” none â€”"] + list(custom_aliases.keys()),
                )
                if st.button("ğŸ—‘ï¸ Delete") and del_key != "â€” none â€”":
                    del custom_aliases[del_key]
                    save_custom_aliases(custom_aliases)
                    st.cache_data.clear()
                    st.success(f"Deleted: {del_key}")
                    st.rerun()
            else:
                st.caption("No custom aliases yet.")

            st.markdown("---")
            st.markdown("**ğŸ“š Built-in Alias Table (from code)**")
            builtin_df = pd.DataFrame(
                sorted(SCHOOL_ALIASES_BUILTIN.items(), key=lambda x: x[1]),
                columns=["Alias (Raw)", "Canonical Name"],
            )
            st.dataframe(builtin_df, use_container_width=True)

        # â”€â”€ DATA TABLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("---")
        st.header("ğŸ“‹ All Responses")

        search = st.text_input("ğŸ” Search by name, school, or class")
        if search:
            display_df = filtered_df[
                filtered_df["full_name"]
                .astype(str)
                .str.contains(search, case=False, na=False)
                | filtered_df["school_name"]
                .astype(str)
                .str.contains(search, case=False, na=False)
                | filtered_df["school_raw"]
                .astype(str)
                .str.contains(search, case=False, na=False)
                | filtered_df["class_name"]
                .astype(str)
                .str.contains(search, case=False, na=False)
            ]
        else:
            display_df = filtered_df

        st.dataframe(display_df, use_container_width=True, height=400)

        # â”€â”€ EXPORT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        st.markdown("---")
        col_dl, _ = st.columns([1, 3])
        with col_dl:
            csv = display_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                label="ğŸ“¥ Download CSV",
                data=csv,
                file_name=f"survey_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv",
            )

    except Exception as e:
        st.error(f"Error: {e}")
        st.exception(e)


if __name__ == "__main__":
    main()
